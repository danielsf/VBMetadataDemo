{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "absent-sleeping",
   "metadata": {},
   "source": [
    "Copy Wayne's\n",
    "```\n",
    "/allen/aibs/technology/waynew/behavior/behavior_only_nwb/20210227_visual_behavior_big_table.csv\n",
    "```\n",
    "into `data/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-article",
   "metadata": {},
   "source": [
    "To run this off-premises, you will also need to set up an ssh tunnel connecting your local machine to the test warehouse, i.e.\n",
    "```\n",
    "ssh -L 8080:testwarehouse:9000 your.username@synapse.corp.alleninstitute.org\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-daily",
   "metadata": {},
   "source": [
    "Define a class (that really just wraps pandas) to do the manipulation of the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handed-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests_toolbelt.downloadutils import stream\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "from contextlib import closing\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5_checksum(file_path):\n",
    "    checker = hashlib.md5()\n",
    "    with open(file_path, 'rb') as in_file:\n",
    "        chunk = in_file.read(1000000)\n",
    "        while len(chunk)>0:\n",
    "            checker.update(chunk)\n",
    "            chunk = in_file.read(1000000)\n",
    "    return checker.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solid-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataCache(object):\n",
    "\n",
    "    def update_manifest(self):\n",
    "        \"\"\"\n",
    "        Write contents of self._manifest to self._manifest_path\n",
    "        \"\"\"\n",
    "        with open(self._manifest_path, 'w') as out_file:\n",
    "            out_file.write(json.dumps(self._manifest, indent=2, sort_keys=True))\n",
    "\n",
    "    def _download_file(self, file_url, file_path):\n",
    "        \"\"\"\n",
    "        Actually download the file from file_url and save\n",
    "        it to file_path\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with closing(requests.get(file_url, stream=True)) as response:\n",
    "                response.raise_for_status()\n",
    "                with open(file_path, 'wb') as out_file:\n",
    "                    stream.stream_response_to_file(response, path=out_file)\n",
    "        except:\n",
    "            if os.path.exists(file_path):\n",
    "                os.unlink(file_path)\n",
    "            raise\n",
    "\n",
    "    def _check_for_file(self, file_url, file_version):\n",
    "        \"\"\"\n",
    "        Returns True if the file has already been downloaded;\n",
    "        False otherwise\n",
    "        (Will also return False if the md5 checksum of the file on\n",
    "        disk is not what the manifest says to expect)\n",
    "        \"\"\"\n",
    "        if file_version not in self._manifest:\n",
    "            return False\n",
    "\n",
    "        if file_url not in self._manifest[file_version]:\n",
    "            return False\n",
    "\n",
    "        target_checksum = self._manifest[file_version][file_url]['md5_checksum']\n",
    "        file_path = self._manifest[file_version][file_url]['file_path']\n",
    "        checksum = get_md5_checksum(file_path)\n",
    "\n",
    "        if checksum != target_checksum:\n",
    "            warnings.warn('checksum changed; deleting old file')\n",
    "            os.unlink(file_path)\n",
    "            self._manifest[file_version].pop(file_url)\n",
    "            self.update_manifest()\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def get_file(self, file_url, file_version):\n",
    "        \"\"\"\n",
    "        file_url -- url to file\n",
    "        file_version -- string denoting version of the file to download\n",
    "                        (not actually sure how we are going to do versioning)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Path to the downloaded file on the local system\n",
    "         \"\"\"\n",
    "\n",
    "        if self._check_for_file(file_url=file_url, file_version=file_version):\n",
    "            return self._manifest[file_version][file_url]['file_path']\n",
    "\n",
    "        print(f\"Actually downloading {file_url} version {file_version}\")\n",
    "\n",
    "        # create a sub directory for files with this version tag\n",
    "        version_dir = os.path.join(self.cache_dir, file_version)\n",
    "        if not os.path.exists(version_dir):\n",
    "            os.makedirs(version_dir)\n",
    "        if not os.path.isdir(version_dir):\n",
    "            raise RuntimeError(f\"\\n{version_dir}\\nis not a directory\")\n",
    "\n",
    "        # the path where we will actually store the downloaded file\n",
    "        file_path = os.path.join(version_dir,\n",
    "                                 os.path.basename(file_url)+'.nwb')\n",
    "            \n",
    "        # make sure it does not exist yet\n",
    "        if os.path.exists(file_path):\n",
    "            raise RuntimeError(f\"\\ntrying to create {file_path}\\nbut it already exists\")\n",
    "            \n",
    "        # download the file\n",
    "        self._download_file(file_url, file_path)\n",
    "\n",
    "        checksum = get_md5_checksum(file_path)\n",
    "        \n",
    "        # update the manifest\n",
    "        if file_version not in self._manifest:\n",
    "            self._manifest[file_version] = {}\n",
    "\n",
    "        self._manifest[file_version][file_url] = {'file_path': file_path,\n",
    "                                                  'md5_checksum': checksum}\n",
    "        self.update_manifest()\n",
    "\n",
    "        return file_path\n",
    "\n",
    "    def get_all_files(self, file_dataframe, file_version='v0'):\n",
    "        \"\"\"\n",
    "        Get all of the files in a dataframe (hopefully a dataframe\n",
    "        that is a result of querying the full dataframe of metdata\n",
    "        associated with this cache)\n",
    "        \"\"\"\n",
    "        output = {}\n",
    "        for file_url in file_dataframe.wkf:\n",
    "            file_url = file_url.replace('testwarehouse:9000', self._warehouse_host)\n",
    "            path = self.get_file(file_url, file_version)\n",
    "            output[file_url] = path\n",
    "        return output\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def dataframe(self):\n",
    "        return self._dataframe\n",
    "\n",
    "    def __init__(self,\n",
    "                 metadata_file = 'data/20210227_visual_behavior_big_table.csv',\n",
    "                 cache_dir = None):\n",
    "        \"\"\"\n",
    "        metadata_file -- path to the metadata csv file\n",
    "        manifest_dir -- directory where manifest of donwloaded files will be kept\n",
    "        \"\"\"\n",
    "\n",
    "        self._warehouse_host = 'localhost:8080'\n",
    "        \n",
    "        self._dataframe = pd.read_csv(metadata_file)\n",
    "\n",
    "        if cache_dir is None:\n",
    "            this_dir = os.path.abspath('')\n",
    "            cache_dir = os.path.join(this_dir, 'data/cache')\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        if not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "\n",
    "        if not os.path.isdir(self.cache_dir):\n",
    "            raise RuntimeError(f\"\\ncache_dir\\n{self.cache_dir}\\nis not a dir\")\n",
    "\n",
    "        self._manifest_path = os.path.join(self.cache_dir, 'manifest.json')\n",
    "        if os.path.exists(self._manifest_path):\n",
    "            if not os.path.isfile(self._manifest_path):\n",
    "                raise RuntimeError(f\"\\nmanifest_path\\n{self._manifest_path}\\nis not a file\")\n",
    "            with open(self._manifest_path, 'rb') as in_file:\n",
    "                self._manifest = json.load(in_file)\n",
    "        else:\n",
    "            warnings.warn(\"Creating new manifest; all data will be re-downloaded\")\n",
    "            self._manifest = {}\n",
    "            self.update_manifest()\n",
    "\n",
    "    def _all_possible(self, column_name):\n",
    "        \"\"\"\n",
    "        List all possible values for a column\n",
    "        \n",
    "        column_name -- a str; the name of the column\n",
    "        \n",
    "        Returns an unsorted set of possible values; returns None of column\n",
    "        does not exist\n",
    "        \"\"\"\n",
    "        if column_name not in self.dataframe.columns:\n",
    "            return None\n",
    "        values = set(self.dataframe[column_name])\n",
    "        return values\n",
    "\n",
    "    def get_all_reporter_lines(self):\n",
    "        return self._all_possible('reporter_line')\n",
    "\n",
    "    def get_all_targeted_structures(self):\n",
    "        return self._all_possible('targeted_structure')\n",
    "\n",
    "    def get_all_genotypes(self):\n",
    "        return self._all_possible('full_genotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "congressional-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = MetadataCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-disability",
   "metadata": {},
   "source": [
    "Try to download an arbitrary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'http://testwarehouse:9000/api/v2/well_known_file_download/1085755199'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.get_file(file_url=uri, file_version='v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-safety",
   "metadata": {},
   "source": [
    "Try to download it again, note that it just returns the path to where it was saved, without donwloading a second time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.get_file(file_url=uri, file_version='v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-steal",
   "metadata": {},
   "source": [
    "List the values for some columns in the metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.get_all_targeted_structures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.get_all_reporter_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competitive-estonia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Slc17a7-IRES2-Cre/wt;Camk2a-tTA/wt;Ai93(TITL-GCaMP6f)/wt',\n",
       " 'Slc17a7-IRES2-Cre/wt;Camk2a-tTA/wt;Ai94(TITL-GCaMP6s)/wt',\n",
       " 'Sst-IRES-Cre/wt;Ai148(TIT2L-GC6f-ICL-tTA2)/wt',\n",
       " 'Vip-IRES-Cre/wt;Ai148(TIT2L-GC6f-ICL-tTA2)/wt'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.get_all_genotypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-minimum",
   "metadata": {},
   "source": [
    "Select a subset of rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "horizontal-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = cache.dataframe.loc[cache.dataframe.full_genotype=='Vip-IRES-Cre/wt;Ai148(TIT2L-GC6f-ICL-tTA2)/wt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "colored-omaha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1476"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollow-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vip-IRES-Cre/wt;Ai148(TIT2L-GC6f-ICL-tTA2)/wt'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(subset.full_genotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "waiting-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "removed-tuner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-insert",
   "metadata": {},
   "source": [
    "Download all of the files in that subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "racial-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actually downloading http://localhost:8080/api/v2/well_known_file_download/1085755589 version v0\n",
      "Actually downloading http://localhost:8080/api/v2/well_known_file_download/1085755636 version v0\n",
      "Actually downloading http://localhost:8080/api/v2/well_known_file_download/1085755699 version v0\n",
      "Actually downloading http://localhost:8080/api/v2/well_known_file_download/1085755676 version v0\n",
      "Actually downloading http://localhost:8080/api/v2/well_known_file_download/1085755697 version v0\n"
     ]
    }
   ],
   "source": [
    "path_map = cache.get_all_files(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-austin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
